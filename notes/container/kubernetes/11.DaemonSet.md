容器守护进程：DaemonSet

DaemonSet的主要作用就是在Kubernetes集群中运行一个Daemon Pod。这个Pod的特征

* 这个Pod运行在Kubernetes集群里的每一个节点（Node）上
* 每个节点上只有一个这样的Pod实例
* 当有新的节点加入Kubernetes集群后，该Pod会自动地在新节点上被创建出来；而当就节点被删除后，它上面的的Pod也相应的被回收掉

**DaemonSet API对象定义分析工作原理**

~~~yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd-elasticsearch
  namespace: kube-system
  labels:
    k8s-app: fluentd-logging
spec:
  selector:
    matchLabels:
      name: fluentd-elasticsearch
  template:
    metadata:
      labels:
        name: fluentd-elasticsearch
    spec:
      tolerations:
      - key: node-role.kubernetes.io/master
        effect: NoSchedule
      containers:
      - name: fluentd-elasticsearch
        image: k8s.gcr.io/fluentd-elasticsearch:1.20
        resources:
          limits:
            memory: 200Mi
          requests:
            cpu: 100m
            memory: 200Mi
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
      terminationGracePeriodSeconds: 30
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
~~~

**DaemonSet如何保证每个Node上有且只有一个被管理的Pod？**

首先DaemonSet Controller从Etcd中获取所有的Node列表，然后遍历所有的Node。检查Node节点上是不是运行有一个携带了name=fluentd-elasticsearch标签的Pod在运行。检查的结果可能存在如下三种情况

* 没有这种Pod，那么就意味着有要在这个Node上创建这样一个Pod

  使用一个是spec.affinity字段，然后定义一个你nodeAffinity

* 有这种Pod，但是数量大于1，那就说明要把多余的Pod从这个Node上删除掉

  直接调用Kubernetes API删除节点是上多余的Pod

* 正好只有一个这种Pod，那说明在这个节点是正常的

在创建每个Pod的时候，DaemonSet会自动给这个Pod加上一个nodeAffinity，从而保证这个Pod只会在指定节点上启动。同时，它还会自动给在这个Pod加上一个Toleration，从而忽略节点的unschedulable"污点"（Taint）

**DaemonSet版本维护**

DaemonSet控制器操作的直接是Pod，不可能有像Deployent中有ReplicaSet对象参与，而是通过ControllerRevision对象，专门用来就记录某种Controller对象的版本。

~~~bash
# kubectl get controllerrevision -n kube-system -l name=fluentd-elasticsearch
NAME                               CONTROLLER                             REVISION   AGE
fluentd-elasticsearch-7474489b7b   daemonset.apps/fluentd-elasticsearch   1          30m

# kubectl rollout history daemonset fluentd-elasticsearch -n kube-system
daemonset.extensions/fluentd-elasticsearch
REVISION  CHANGE-CAUSE
1         <none>
2         kubectl set image ds/fluentd-elasticsearch fluentd-elasticsearch=k8s.gcr.io/fluentd-elasticsearch:v2.2.0 --record=true --namespace=kube-system

# kubectl get controllerrevision -n kube-system -l name=fluentd-elasticsearch
NAME                               CONTROLLER                             REVISION   AGE
fluentd-elasticsearch-7474489b7b   daemonset.apps/fluentd-elasticsearch   1          33m
fluentd-elasticsearch-7bfb65fd9c   daemonset.apps/fluentd-elasticsearch   2          13m

# kubectl describe controllerrevision fluentd-elasticsearch-7bfb65fd9c -n kube-system
Name:         fluentd-elasticsearch-7bfb65fd9c
Namespace:    kube-system
Labels:       controller-revision-hash=7bfb65fd9c
              name=fluentd-elasticsearch
Annotations:  deprecated.daemonset.template.generation: 2
              kubernetes.io/change-cause:
                kubectl set image ds/fluentd-elasticsearch fluentd-elasticsearch=k8s.gcr.io/fluentd-elasticsearch:v2.2.0 --record=true --namespace=kube-sy...
API Version:  apps/v1
Data:
  Spec:
    Template:
      $ Patch:  replace
      Metadata:
        Creation Timestamp:  <nil>
        Labels:
          Name:  fluentd-elasticsearch
      Spec:
        Containers:
          Image:              k8s.gcr.io/fluentd-elasticsearch:v2.2.0
          Image Pull Policy:  IfNotPresent
          Name:               fluentd-elasticsearch
...
Revision:                  2
Events:                    <none>
~~~

这个ControllerRevision对象，实际上是在Data字段保存了该版本的对应的完整的DamonSet的API对象。并且，在Annotation字段保存了创建这个对象所使用的kubectl命令

回滚到Revision=1时的状态

~~~bash
# kubectl rollout undo daemonset fluentd-elasticsearch --to-revision=1 -n kube-system
daemonset.extensions/fluentd-elasticsearch rolled back
~~~

