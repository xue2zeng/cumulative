> 容器本身没有价值，有价值的是“容器编排”

## 容器，到底是怎么一回事儿？

​	容器其实就是一种沙盒技术。顾名思义，沙盒就是能够像一个集装箱一样，把开发的应用“装”起来的技术。这样应用与应用之间就因为有了边界而不至于相互干扰。而被装进集装箱的应用，也可以被方便地搬来搬去，这不就是PaaS最理想的状态嘛

### 进程

​	程序（代码的可执行镜像）被执行起来，它从磁盘的二进制文件变成了计算机内存中的数据、寄存器里的值、堆栈中的指令、被打开的文件，以及各种设备的状态信息的一个集合。像这样一个程序运行起来后的计算机执行环境的总和，称为操作系统的进程

​	对于进程而言，它的静态表现就是程序，平常都安安静静地待在磁盘上；而一旦运行起来，它就变成了计算机里的数据和状态的总和，这就是它的动态表现。

### 容器技术核心功能

##### 通过约束和修改进程的动态表现，从而为其创造出一个“边界”

* Cgroups（Control groups）技术是用来制造约束的主要手段

  主要作用就是限制一个进程组能够使用的资源上线，包括CPU、内存、磁盘、网络宽带等

  Cgroups给用户暴露出来的操作接口是文件系统，即它以文件和目录的方式组织在操作系统的/sys/fs/cgroup路径下

  ~~~bash
  # mount -t cgroup
  cgroup on /sys/fs/cgroup/systemd type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,xattr,release_agent=/usr/lib/systemd/systemd-cgroups-agent,name=systemd)
  cgroup on /sys/fs/cgroup/perf_event type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,perf_event)
  cgroup on /sys/fs/cgroup/pids type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,pids)
  cgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,cpuacct,cpu)
  cgroup on /sys/fs/cgroup/net_cls,net_prio type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,net_prio,net_cls)
  cgroup on /sys/fs/cgroup/memory type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,memory)
  cgroup on /sys/fs/cgroup/blkio type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,blkio)
  cgroup on /sys/fs/cgroup/devices type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,devices)
  cgroup on /sys/fs/cgroup/hugetlb type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,hugetlb)
  cgroup on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,cpuset)
  cgroup on /sys/fs/cgroup/freezer type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,freezer)
  ~~~

  以CPU子目录（子系统）来说

  ~~~bash
  # ls /sys/fs/cgroup/cpu
  cgroup.clone_children  cgroup.procs          cpuacct.stat   cpuacct.usage_percpu  cpu.cfs_quota_us  cpu.rt_runtime_us  cpu.stat  notify_on_release  system.slice  user.slice
  cgroup.event_control   cgroup.sane_behavior  cpuacct.usage  cpu.cfs_period_us     cpu.rt_period_us  cpu.shares   release_agent      tasks
  ~~~

  在该目录下创建一个目录，这个目录就称为一个“控制组”。操作系统会在新建的container目录下自动生成该子系统对应的资源限制文件

  ~~~bash
  # mkdir container
  # ls
  cgroup.clone_children  cgroup.procs  cpuacct.usage         cpu.cfs_period_us  cpu.rt_period_us   cpu.shares  notify_on_release
  cgroup.event_control   cpuacct.stat  cpuacct.usage_percpu  cpu.cfs_quota_us   cpu.rt_runtime_us  cpu.stat    tasks
  ~~~

  执行如下脚本，可以把计算机的CPU吃到100%，根据它的输出可以看到这个脚本在后台的进程号（PID）是23378

  ~~~bash
  # while : ; do : ; done &
  [1] 23378
  # top
  %Cpu0 :100.0 us, 0.0 sy, 0.0 ni, 0.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st
  ~~~

  通过查看container目录下的文件，看到container控制组里的CPU quota还没有任何限制（即：-1），CPU period则是默认的100ms（100000us）

  ~~~bash
  # cat /sys/fs/cgroup/cpu/container/cpu.cfs_quota_us 
  -1
  # cat /sys/fs/cgroup/cpu/container/cpu.cfs_period_us 
  100000
  ~~~

  通过修改这些文件的内容来设置限制。向container组里的cfs_quata文件写入20ms（20000us），把被限制的进程的PID写入container组里的tasks文件，上面的设置就会对该进程生效

  ~~~bash
  # echo 20000 > /sys/fs/cgroup/cpu/container/cpu.cfs_quota_us
  # echo 23378 > /sys/fs/cgroup/cpu/container/tasks 
  # top
  %Cpu0 : 20.3 us, 0.0 sy, 0.0 ni, 79.7 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st
  ~~~

  对于Docker等Linux容器来说，它们只需要在每个子系统下面为每个容器创建一个“控制组”（即创建一个新目录），然后在启动容器进程之后，把这个进程的PID填写到对应控制组的tasks文件中就可以了。控制组下面的资源文件里面填上什么值，就靠用户执行docker run时的参数来指定

  ~~~bash
  # docker run -it --cpu-period=100000 --cpu-quota=20000 busybox /bin/bash
  # cat /sys/fs/cgroup/cpu/docker/3c345c23e033a387841e2903a509ba888b8f11cfed8218268204f2b11d8a6f4f/cpu.cfs_period_us 
  100000
  # cat /sys/fs/cgroup/cpu/docker/3c345c23e033a387841e2903a509ba888b8f11cfed8218268204f2b11d8a6f4f/cpu.cfs_quota_us 
  20000
  ~~~

  这就意味着这个Docker容器，只能使用到20%的CPU宽带

* Namespace技术是用来修改进程视图的主要手段

  通过Linux系统本质来理解这两项技术

  尝试创建一个容器

  ~~~bash
  # docker run -it busybox /bin/sh
  / # 
  ~~~

  在容器中执行ps指令

  ~~~bash
  / # ps
  PID   USER     TIME  COMMAND
      1 root      0:00 /bin/sh
      6 root      0:00 ps
  / #
  ~~~

  在宿主机执行ps指令

  ~~~bash
  # ps
    PID TTY          TIME CMD
   4836 pts/0    00:00:00 su
   5136 pts/0    00:00:00 bash
   6471 pts/0    00:00:00 sh
   6814 pts/0    00:00:00 ps
  ~~~

  可以看出Docker里最开始执行的/bin/sh，就是这个容器内部的第1号进程，而这个容器里一共只有两个进程在运行。同时宿主机上对应的容器运行的进程号为6471，Docker已经与宿主机进行了完全的隔离。这种机制，其实就是对被隔离的应用的进程空间做了手脚，使得这些进程只能看到重新计算过的进程编号。实际上在宿主机的操作系统里，还是原来的第6471进程。这种技术就是Linux里面的Namespace机制

  Linux系统中创建线程的系统调用是clone()

  ~~~bash
  int pid = clone(main_function, stack_size, SIGCHLD, NULL); 
  ~~~

  利用Linux调用clone创建新进程时，在一个可选参数中指定CLONE_NEWPID 参数

  ~~~bash
  int pid = clone(main_function, stack_size, CLONE_NEWPID | SIGCHLD, NULL); 
  ~~~

  这时新创建的进程将会“看到”一个全新的进程空间，在这个进程空间里它的PID就是1

  除了上述的PID Namespace，Linux操作系统还提供了Mount、UTS、IPC、Network和User等Namespace，用来对各种不同的进程上下文进行“障眼法”操作

  ​	Mount Namespace：用于让被隔离进程只看到当前Namespace里的挂载点信息

  ​	Network Namespace：用于让被隔离进程只看到当前Namespace里的网络设备和配置

  上述就是Linux容器最基本的实现原理。所以说，**容器**，其实是一种特殊额进程而已

  容器相对于虚拟机最大的优势在于**"敏捷"**和**"高性能"**。然而基于Linux Namesapce的隔离机制相比于虚拟化技术的不足之处在于：隔离的不彻底，在Linux中有很多资源和对象是不能被Namesapce化的，最典型的例子就是：时间。相比于在虚拟机中可以随便折腾的自由度，而在容器里部署应用时，”什么能做，什么不能做“，就是用户必须考虑的一个问题。

### 深入理解容器镜像

##### 理解Linux chroot

* chroot：顾名思义，它的作用就是帮你“change root file system”，即改变进程的根目录到你指定的位置

* 实例使用：创建一个$HOME/test目录，把它作为/bin/bash进程的根目录

  * 创建一个test目录和几个lib文件夹

    ~~~bash
    # mkdir -p $HOME/test
    # mkdir -p $HOME/test/{bin,lib64,lib}
    # cd $T
    ~~~

  * 把bash命令拷贝到test目录对应的bin路径下

    ~~~bash
    # cp -v /bin/{bash,ls} $HOME/test/bin
    ~~~

  * 把bash命令需要的所有so文件也拷贝到test目录对应的lib路径下。找到so文件可以用ldd命令

    ~~~bash
    # T=$HOME/test
    # list="$(ldd /bin/ls | egrep -o '/lib.*\.[0-9]')"
    # for i in $list; do cp -v "$i" "${T}${i}"; done
    ~~~

  * 执行chroot命令，告诉操作系统使用$HOME/test目录作为/bin/bash进程的根目录

    ~~~bash
    # chroot $HOME/test /bin/bash
    ~~~

  * 此时执行“ls /”指令，就会看到它返回的都是$HOME/test目录下面的内容，而不是宿主机的内容

  Mount Namespace基于对Linux chroot的不断改良才被发明出来，它也是Linux操作系统里的第一个Namespace

​	在容器启动之后，通过在容器里执行“ls /”查看根目录下的内容，其实就是挂载了一个完整的操作系统的文件系统。而这个挂载在容器根目录上、用来为容器进程提供隔离后执行环境的文件系统，就是所谓的“容器镜像”。它还有一个更为专业的名字，叫作：rootfs（根文件系统）。常见的rootfs会包括如下所示的一些目录和文件

~~~bash
# ls
bin  boot  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var
~~~

​	rootfs只是一个操作系统所包含的文件、配置和目录，并不包括操作系统内核。在Linux操作系统中，这两部分是分开存放的，操作系统只有在开机启动时才会加载指定版本的内核镜像。所以说，rootfs只包括了操作系统的“躯壳”，并没有包括操作系统的“灵魂”。

##### 核心原理

对于Docker项目来说，它最核心的原理实际上就是为待创建的用户进程

* 启用Linux Namespace配置
* 设置指定的Cgroups参数
* 切换进程的根目录（Change Root）

一个完整的容器就诞生了。不过，Docker项目在最后一步的切换上会优先使用pivot_root系统调用，如果系统不支持，才会使用chroot

##### 容器的“一致性”

rootfs里打包的不只是应用，而是整个操作系统的文件和目录，也就意味着应用以及它运行所需要的所有依赖都被封装在了一起。对于一个应用来说，操作系统本身才是它运行所需要的最完整的“依赖库”。有了容器镜像“打包操作系统”的能力，这个最基础的依赖环境也终于变成了应用沙盒的一部分。这就赋予了容器所谓的**一致性**：无论在本地、云端，还是在一台任何地方的机器上，用户只需要解压打包好的容器镜像，那么这个应用运行所需要的完整可执行环境就被重现出来了。

这种深入到操作系统级别的运行环境一致性，打通了应用在本地开发和远端执行环境之间难以逾越的鸿沟

一旦镜像被发布，那么在世界的任何一个地方下载该镜像，得到的内容都完全一致，可以完全复现这个镜像制作者当初的完整环境。所以，这就是容器技术“强一致性”的重要体现。

##### 层（layer）

**每开发一个应用，或者升级一下现有的应用，都需要重复制作一次rootfs吗?**

Docker在镜像设计中，引入层的概念。用户制作镜像的每一步操作，都会生成一个层，也就是一个增量rootfs。用到了一种叫作联合文件系统（Union File System）的能力。

Docker默认使用overlay2作为存储，可以通过docker info命令查看到这个信息

~~~bash
[root@node1 aufs]# docker info
...
Server Version: 18.06.1-ce
Storage Driver: overlay2
 Backing Filesystem: xfs
 Supports d_type: true
 Native Overlay Diff: true
Logging Driver: json-file
Cgroup Driver: cgroupfs
...
~~~

最关键的目录结构在 /var/lib/docker/overlay2 路径下的diff目录

~~~bash
/var/lib/docker/overlay2/<layer_id>diff
~~~

启动一个Ubuntu容器

~~~bash
# docker run -d ubuntu:latest sleep 3600
~~~

这时Docker会从Docker Hub上拉取一个Ubuntu镜像到本地。这个镜像，实际上就是一个Ubuntu操作系统的rootfs，它的内容是Ubuntu操作系统的所有文件和目录。Docker镜像使用的rootfs，往往是由多个“层”组成

~~~bash
# docker image inspect ubuntu:latest
[
    {
        ...
        "RootFS": {
            "Type": "layers",
            "Layers": [
                "sha256:a30b835850bfd4c7e9495edf7085cedfad918219227c7157ff71e8afe2661f63",
                "sha256:6267b420796f78004358a36a2dd7ea24640e0d2cd9bbfdba43bb0c140ce73567",
                "sha256:f73b2816c52ac5f8c1f64a1b309b70ff4318d11adff253da4320eee4b3236373",
                "sha256:6a061ee02432e1472146296de3f6dab653f57c109316fa178b40a5052e695e41",
                "sha256:8d7ea83e3c626d5ef1e6a05de454c3fe8b7a567db96293cb094e71930dba387d"
            ]
        ...
    }
]
~~~

可以看出这个Ubuntu镜像，实际上由五个层组成。这个五个层就是五个增量rootfs，每一层都是Ubuntu操作系统文件和目录的一部分，通过命令查看文件系统内容

~~~bash
# ls -l /var/lib/docker/overlay2
drwx------. 4 root root     55 Oct 18 01:58 456cdc6f537b9e82acd6ddd1e372c5a76c89d80e5f4251af17790e1d6ef9880d
drwx------. 4 root root     55 Oct 18 01:58 5ab03cceea70617e849128e1048868acd573eff72bd78da35bb737dca791078f
drwx------. 3 root root     30 Oct 18 01:58 68db37540d07e0dbb223fd5d87e4207caa0bf0f47d5c46b772a92f65fb334382
drwx------. 4 root root     55 Oct 18 01:58 74899840d9bbce015d0d22ca7219b3b0fd92c37ffcd281d17ceeace8c45bad26
drwx------. 4 root root     55 Oct 18 01:58 c3ae304d4f3fc4fc220a34bead60c87dcafbd4ef057a0efda36c1f68ebad9746
drwx------. 4 root root     55 Oct 18 02:58 de5f7aeffec82b570aa77d50a6669047c0b5fc03785b73554d3502e75b25c3e8
drwx------. 4 root root     55 Oct 18 01:58 de5f7aeffec82b570aa77d50a6669047c0b5fc03785b73554d3502e75b25c3e8-init
drwx------. 2 root root    244 Oct 18 01:58 l
~~~

在容器的rootfs最上面的一层（de5f7aeffec82b570aa77d50a6669047c0b5fc03785b73554d3502e75b25c3e8），在没有写入之前，这个目录下的diff目录是空的。而一旦在容器里做了写操作，修改产生的内容就会以增量的方式出现在这个层中。所以，最上面这个可读写层的作用就是专门用来存放修改rootfs后产生的增量，无论是增、删、改都发生在这里。当使用完这个这个被修改过的容器之后，就可以使用docker commit和push命令保存这个被修改过的可读写层，并上传至Docker Hub或者私有库，供其他人使用。而与此同时，原先的只读层里的内容则不会有任何变法，这就是增量rootfs的好处。

init层是Docker项目单独生成的一个内部层，专门用来存放/etc/hosts、/etc/resolv.conf等信息。需要这层的原因就是用户往往需要在启动容器时写入一些指定的值比如：hostname，所以需要在这层对它们进行修改。可是这些修改往往只对当前的容器有效，并不希望执行docker commit时把这些信息连同可读写层一起提交。所以，Docker的做法就是在修改这些文件后，以一个单独的层挂载出来。而用户执行docker commit只会提交最上可以写层，而不包含该层修改的内容。

新的l（小写的L）目录包含了上述层标识符的缩短链接

~~~bash
# ls -l /var/lib/docker/overlay2/l
lrwxrwxrwx. 1 root root 72 Oct 18 01:58 2GIMGHIHEQ6CHNG4DVWSPAOIGR -> ../c3ae304d4f3fc4fc220a34bead60c87dcafbd4ef057a0efda36c1f68ebad9746/diff
lrwxrwxrwx. 1 root root 72 Oct 18 01:58 5JZRTP6RNSRQFPDCQ5VGPUX6C7 -> ../74899840d9bbce015d0d22ca7219b3b0fd92c37ffcd281d17ceeace8c45bad26/diff
lrwxrwxrwx. 1 root root 72 Oct 18 01:58 CTPHL2PNOIQS3HXH3NDIVKLMVX -> ../5ab03cceea70617e849128e1048868acd573eff72bd78da35bb737dca791078f/diff
lrwxrwxrwx. 1 root root 72 Oct 18 01:58 DWEQ4Q5K26YSTMSAGMMDEJ5QSZ -> ../68db37540d07e0dbb223fd5d87e4207caa0bf0f47d5c46b772a92f65fb334382/diff
lrwxrwxrwx. 1 root root 72 Oct 18 01:58 J6ZVDRDUWZ2OCEGIL5HXRAVWAV -> ../de5f7aeffec82b570aa77d50a6669047c0b5fc03785b73554d3502e75b25c3e8/diff
lrwxrwxrwx. 1 root root 72 Oct 18 01:58 KQ3EENTNMCA5LRDQIEMCTUCAJM -> ../456cdc6f537b9e82acd6ddd1e372c5a76c89d80e5f4251af17790e1d6ef9880d/diff
lrwxrwxrwx. 1 root root 77 Oct 18 01:58 LVMRZEGWA5XOMQRVG4S7OZP7GW -> ../de5f7aeffec82b570aa77d50a6669047c0b5fc03785b73554d3502e75b25c3e8-init/diff
~~~

最低层包含一个名为link的文件，其中包含缩短链接的标识符，以及一个名为diff的目录，其中包含图层的内容

~~~bash
# ls /var/lib/docker/overlay2/68db37540d07e0dbb223fd5d87e4207caa0bf0f47d5c46b772a92f65fb334382
diff  link
# cat /var/lib/docker/overlay2/68db37540d07e0dbb223fd5d87e4207caa0bf0f47d5c46b772a92f65fb334382/link
DWEQ4Q5K26YSTMSAGMMDEJ5QSZ
# ls /var/lib/docker/overlay2/68db37540d07e0dbb223fd5d87e4207caa0bf0f47d5c46b772a92f65fb334382/diff
bin  boot  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var

~~~

第二层和更高层次都包含一个名为lower文件，表示其父级，以及一个名为diff的当前层文件内容，还有一个由OverlayFS在内部使用的工作目录

~~~bash
# ls /var/lib/docker/overlay2/5ab03cceea70617e849128e1048868acd573eff72bd78da35bb737dca791078f
diff  link  lower  work
# cat /var/lib/docker/overlay2/5ab03cceea70617e849128e1048868acd573eff72bd78da35bb737dca791078f/lower
l/DWEQ4Q5K26YSTMSAGMMDEJ5QSZ
# ls /var/lib/docker/overlay2/5ab03cceea70617e849128e1048868acd573eff72bd78da35bb737dca791078f/diff
etc  sbin  usr  var
~~~

通过mount命令查看挂载信息（或者直接查看系统挂载文件内容cat /proc/mounts| grep overlay）

~~~bash
# mount | grep overlay
overlay on /var/lib/docker/overlay2/afe950ccd0af701a25604d98375b67fc55c923c36a0cf812d539fc65ee2fa248/merged type overlay (rw,relatime,seclabel,lowerdir=/var/lib/docker/overlay2/l/SYM4EADTJHV7VPSNMSIL2SEB2I:/var/lib/docker/overlay2/l/2GIMGHIHEQ6CHNG4DVWSPAOIGR:/var/lib/docker/overlay2/l/KQ3EENTNMCA5LRDQIEMCTUCAJM:/var/lib/docker/overlay2/l/5JZRTP6RNSRQFPDCQ5VGPUX6C7:/var/lib/docker/overlay2/l/CTPHL2PNOIQS3HXH3NDIVKLMVX:/var/lib/docker/overlay2/l/DWEQ4Q5K26YSTMSAGMMDEJ5QSZ,upperdir=/var/lib/docker/overlay2/afe950ccd0af701a25604d98375b67fc55c923c36a0cf812d539fc65ee2fa248/diff,workdir=/var/lib/docker/overlay2/afe950ccd0af701a25604d98375b67fc55c923c36a0cf812d539fc65ee2fa248/work)
~~~

最终在Docker容器中所看到的所挂载的一个完整的Ubuntu操作系统文件内容就是如下目录，该目录实际上是容器挂载点

~~~bash
# ls /var/lib/docker/overlay2/afe950ccd0af701a25604d98375b67fc55c923c36a0cf812d539fc65ee2fa248/merged
bin  boot  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var
~~~

如下视图显示了Docker如何构造映射到OverlayFS结构

![overlay工作结构图](./images/overlay_constructs.jpg)

QA

* 既然容器的 rootfs（比如，Ubuntu 镜像），是以只读方式挂载的，那么又如何在容器里修改Ubuntu镜像的内容呢？

  上面的读写层通常称为容器层，下面的只读层称为镜像层，所有的增删改操作都只会作用在容器层，相同的文件上层会覆盖掉下层。知道这点就不难理解镜像文件的修改。比如修改一个文件时，首先会从上至下查找有没有这个文件，找到，就复制到容器层中修改，修改的结果就会作用到下层的文件，这种方式就被称为copy-on-write

